{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 16:14:52.717763: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-20 16:14:52.718146: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-20 16:14:52.720195: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-20 16:14:52.726129: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734707692.738059   10890 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734707692.741306   10890 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-20 16:14:52.752838: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "#from keras.applications import ResNet50\n",
    "#from keras.applications.resnet import decode_predictions, preprocess_input \n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helpers import *\n",
    "\n",
    "# Load environment variables from the secret.env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables using os.getenv() or os.environ\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "api_url = os.getenv(\"API_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['InceptionResNetV2', 'ResNet101', 'ResNet101V2', 'ResNet152', 'ResNet152V2', 'ResNet50', 'ResNet50V2', 'inception_resnet_v2', 'resnet', 'resnet50', 'resnet_v2']\n"
     ]
    }
   ],
   "source": [
    "available_models = [name for name in dir(tf.keras.applications) if 'resnet' in name.lower()]\n",
    "print(available_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'ResNet101' found in tf.keras.applications.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 16:14:54.810900: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base_model 'ResNet101' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "#model_name = \"ResNet50\"  # Can be ResNet101, ResNet50V2, etc.\n",
    "model_name = \"ResNet101\"\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "base_model = load_resnet_basemodel(model_name, input_shape=input_shape)\n",
    "\n",
    "# Display the model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get images through API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"vine\"\n",
    "start_date = \"2020-08-01\"\n",
    "end_date = \"2021-01-01\"\n",
    "tags = ['grass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tag = \"vine\"\\nstart_date = \"2014-01-01\"\\nend_date = \"2025-01-01\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''tag = \"vine\"\n",
    "start_date = \"2014-01-01\"\n",
    "end_date = \"2025-01-01\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['vine']\n",
    "#tags = ['vine', 'grass', 'ground']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of urls collected for vine: 23\n"
     ]
    }
   ],
   "source": [
    "image_urls = get_image_urls_with_multiple_tags(tags, start_date, end_date, api_key, api_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download image for urls and make the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Signature=55709ae943dabb1c89e8be508f697c7eb8342d0f downloaded successfully\n",
      "Image Signature=fbaeea5561997a82eb6cb99b1f9ba57d1325f0c9 downloaded successfully\n",
      "Image Signature=57abdd6461226256b56d990610eda14eca8626dc downloaded successfully\n",
      "Image Signature=4b7440f33e4ad8c49f1338297325f25abe01e43e downloaded successfully\n",
      "Image Signature=884c68fbcf4d08c44aba91f8829d08cefe968369 downloaded successfully\n",
      "Image Signature=89675e227e2db65e862fd95a662025137aec2948 downloaded successfully\n",
      "Image Signature=1e78767e068341b78940a1c28d0a4af7141f08f6 downloaded successfully\n",
      "Image Signature=7c1eca2cf95b6937e9a99e6ffe8deea98dcfa266 downloaded successfully\n",
      "Image Signature=25edfd8287cfaa82f1a06ca48344b0ddd2428360 downloaded successfully\n",
      "Image Signature=148182e3be8c7cc5e51cf4cd90be18ce890d7e83 downloaded successfully\n",
      "Image Signature=3f162a4fef6bde2bd4492d4f8c27438145f66582 downloaded successfully\n",
      "Image Signature=2507355b43bee932ba58d564c6354c431e226f8f downloaded successfully\n",
      "Image Signature=32c3d385be92ef67157661c64711ebdfe855e390 downloaded successfully\n",
      "Image Signature=e8d7cfa7530d84812f786c84b6de2bac432c6ebc downloaded successfully\n",
      "Image Signature=1577d5c930aa3a1f1915d072adb3534942a3c637 downloaded successfully\n",
      "Image Signature=72ef26b8d3cb236a0a19750008b85829c704615f downloaded successfully\n",
      "Image Signature=fa863df76723773eb5a001b4c0a4f85d8c57037c downloaded successfully\n",
      "Image Signature=8e33cbb2d3ea19f3cffe945a4d4baa7e52c4eb4f downloaded successfully\n",
      "Image Signature=af9027cd0ca3d3e410f796be941c4eefe871a69f downloaded successfully\n",
      "Image Signature=6ccb3798d36afc12e66bc33ccb8369676f515130 downloaded successfully\n",
      "Image Signature=8462eb9ff80cc6c2c1e9f4d490cfb48d9b085ca7 downloaded successfully\n",
      "Image Signature=04737edbbe2f6fcc1ca0def78b3f977c166f391a downloaded successfully\n",
      "Image Signature=5ccc8dfafc1a6c4615d560f2898a147780b9f3d9 downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "df_sample_map = download_images_and_create_sample_map(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"media\"\n",
    "image_paths, encoded_labels = create_path_list_and_encoded_label(df_sample_map, image_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess_input function for 'ResNet101' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "random_state = 42\n",
    "test_size = 0.2\n",
    "train_dataset, val_dataset = make_train_test_dataset(image_paths, encoded_labels, test_size=test_size, random_state=random_state, batch_size=batch_size, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.5222 - loss: 0.9655 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fcaec3cbd10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ResNet50 model pre-trained on ImageNet\n",
    "#base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Allowing the base model to be trained for better performance\n",
    "base_model.trainable = True\n",
    "\n",
    "# Add custom layers on top\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 1\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_3\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(224, 224, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     20\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 21\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/envs/chouette_project/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/envs/chouette_project/lib/python3.12/site-packages/keras/src/layers/input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"functional_3\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(224, 224, 3)"
     ]
    }
   ],
   "source": [
    "# Load ResNet50 model pre-trained on ImageNet\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Allowing the base model to be trained for better performance\n",
    "base_model.trainable = True\n",
    "\n",
    "# Add custom layers on top\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 1\n",
    "history = model.fit(dataset, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vine_timestamp = [i['timestamp'].split('T')[0] for i in image_urls_vines]\n",
    "image_ground_timestamp = [i['timestamp'].split('T')[0] for i in image_urls_vines]\n",
    "image_grass_timestamp = [i['timestamp'].split('T')[0] for i in image_urls_vines]\n",
    "\n",
    "image_grass_timestamp[:10]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with the timestamps\n",
    "df_timestamps_vine = pd.DataFrame({'date': image_vine_timestamp})\n",
    "df_timestamps_vine['type'] = 'vine'                            \n",
    "df_timestamps_grass = pd.DataFrame({'date': image_grass_timestamp})\n",
    "df_timestamps_grass['type'] = 'grass'\n",
    "df_timestamps_ground = pd.DataFrame({'date': image_ground_timestamp})\n",
    "df_timestamps_ground['type'] = 'ground'\n",
    "df_timestamps = pd.concat([df_timestamps_vine, df_timestamps_grass, df_timestamps_ground])\n",
    "\n",
    "# Convert the timestamps to datetime objects\n",
    "df_timestamps['date'] = pd.to_datetime(df_timestamps['date'])\n",
    "\n",
    "# Group by Date and count unique classes\n",
    "unique_type_per_day = df_timestamps.groupby(['date', 'type'], as_index=False).agg(lambda x: x.shape[0])\n",
    "\n",
    "unique_type_per_day.columns = ['date', 'type', 'count']\n",
    "unique_type_per_day.plot(x='date', y='count', kind='bar', figsize=(15, 6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chouette_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
